{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import sklearn\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('vectors/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_word(word):\n",
    "\tif word in model.wv:\n",
    "\t\treturn pd.Series(model.wv[word])\n",
    "\telse:\n",
    "\t\t# The pretrained word2vec model has dimensionality 300\n",
    "\t\treturn pd.Series([np.nan] * 300)\n",
    "def merge_vectors(v1, v2, method):\n",
    "\tprint \"method\", method\n",
    "\t# Concat\n",
    "\tif method == 'concat':\n",
    "\t\treturn pd.concat([v1, v2, y], axis = 1)\n",
    "\telif method == 'diff':\n",
    "\t\t# Roller 2014 says to normalize the difference\n",
    "\t\tdiff = v1 - v2\n",
    "\t\treturn pd.concat([diff, y], axis = 1)\n",
    "\telif method == 'asym':\n",
    "\t\tprint \"asym\"\n",
    "\t\t# diff\n",
    "\t\ta = v1 - v2\n",
    "\t\t# squared diff - can't tell if they mean the mag^2 or ea element sq?\n",
    "\t\tb = pd.DataFrame(np.sqrt(np.square(a.values).sum(axis=1)))\n",
    "\t\treturn pd.concat([a, b, y], axis = 1)\n",
    "\telif method == 'cosine':\n",
    "\t\t#this fails???\n",
    "\t\tprint \"cosine\"\n",
    "\t\tcos = pd.DataFrame(cosine_similarity(vectors_0.values, vectors_1.values).diagonal())\n",
    "\t\treturn pd.concat([v1, v2, cos, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method concat\n",
      "method concat\n",
      "method concat\n"
     ]
    }
   ],
   "source": [
    "folder = 'turney2014'\n",
    "method = 'concat'\n",
    "for subset in ['test', 'train', 'val']:\n",
    "    path_to_dataset = 'lexical_entailment/' + folder + '/data_lex_' + subset + '.tsv'\n",
    "    path_to_vectorized = 'lexical_entailment/' + folder + '/data_lex_' + subset + '_vectorized.tsv'\n",
    "    df = pd.read_csv(path_to_dataset, sep='\\t', header=None)\n",
    "    words_0 = df[0]\n",
    "    words_1 = df[1]\n",
    "    y = df[[2]]\n",
    "    vectors_0 = words_0.apply(vectorize_word)\n",
    "    vectors_1 = words_1.apply(vectorize_word)\n",
    "    vectors_x = merge_vectors(vectors_0, vectors_1, method)\n",
    "    vectors_x.to_csv(path_to_vectorized, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test : percentage non-nan correct: 0.923381396664\n",
      "test : percentage correct overall 0.894794520548\n",
      "val : percentage non-nan correct: 0.931343283582\n",
      "val : percentage correct overall 0.871508379888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = joblib.load('models/svm.pkl') \n",
    "\n",
    "test_vectorized = pd.read_csv('lexical_entailment/bless2011/data_lex_test_vectorized.tsv', sep='\\t', header=None)\n",
    "val_vectorized = pd.read_csv('lexical_entailment/bless2011/data_lex_val_vectorized.tsv', sep='\\t', header=None)\n",
    "\n",
    "# Test and validation in one go bc i'm lazy\n",
    "for test_name, test_df in zip(['test', 'val'], [test_vectorized, val_vectorized]):\n",
    "\torig_rows, orig_cols = test_df.shape\n",
    "\n",
    "\t# Remove rows with NaN\n",
    "\ttest_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "\t# Count number of rows removed\n",
    "\tdiff = orig_rows - test_df.shape[0]\n",
    "\n",
    "\tX = test_df.iloc[:, :-1]\n",
    "\ty = test_df.iloc[:, -1]\n",
    "\n",
    "\tpreds = clf.predict(X)\n",
    "\n",
    "\tnum_correct = accuracy_score(y, preds, normalize=False)\n",
    "\n",
    "\tprint test_name, \": percentage non-nan correct:\", num_correct/float(test_df.shape[0]) \n",
    "\tprint test_name, \": percentage correct overall\", num_correct/float(orig_rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('lexical_entailment/bless2011/data_lex_train_vectorized_asym.tsv', sep='\\t', header=None)\n",
    "train.dropna(axis=0, inplace=True)\n",
    "X = train.iloc[:, :-1]\n",
    "y = train.iloc[:, -1]\n",
    "\n",
    "clf = svm.LinearSVC(class_weight='balanced')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectorized = pd.read_csv('lexical_entailment/bless2011/data_lex_test_vectorized_asym.tsv', sep='\\t', header=None)\n",
    "test = pd.read_csv('lexical_entailment/bless2011/data_lex_test.tsv', sep='\\t', header=None)\n",
    "val_vectorized = pd.read_csv('lexical_entailment/bless2011/data_lex_val_vectorized_asym.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = val_vectorized\n",
    "test_df = test_vectorized\n",
    "train_df.dropna(axis=0, inplace=True)\n",
    "test_df.dropna(axis=0, inplace=True)\n",
    "X = train_df.iloc[:, :-1]\n",
    "y = train_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.806451612903\n",
      "recall 0.892857142857\n",
      "f1 0.847457627119\n",
      "True 0.892857142857\n",
      "False 0.980456026059\n"
     ]
    }
   ],
   "source": [
    "print \"precision\", metrics.precision_score(y, preds)\n",
    "print \"recall\", metrics.recall_score(y, preds)\n",
    "print \"f1\", metrics.f1_score(y, preds)\n",
    "print \"True\", metrics.accuracy_score(y[y == 1], preds[y == 1])\n",
    "print \"False\", metrics.accuracy_score(y[y == 0], preds[y == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_hat = clf.coef_[0][:301]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "  '''normalize' a vector, in the traditional linear algebra sense.'''\n",
    "  norm=np.linalg.norm(v)\n",
    "  if norm==0:\n",
    "    return v\n",
    "  return v/norm\n",
    "def reject(A):\n",
    "\n",
    "  '''Create a 'projection', and subract it from the original vector'''\n",
    "  B = p_hat\n",
    "  project = np.linalg.linalg.dot(A, normalize(B)) * normalize(B)\n",
    "  return A - project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = X.apply(reject, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_hat = svm.LinearSVC()\n",
    "clf_hat.fit(X_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.416243654822\n",
      "recall 0.30258302583\n",
      "f1 0.350427350427\n",
      "True 0.30258302583\n",
      "False 0.964788732394\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.iloc[:, :-1]\n",
    "y_test = test_df.iloc[:, -1]\n",
    "preds_hat = clf_hat.predict(X_test)\n",
    "print \"precision\", metrics.precision_score(y_test, preds_hat)\n",
    "print \"recall\", metrics.recall_score(y_test, preds_hat)\n",
    "print \"f1\", metrics.f1_score(y_test, preds_hat)\n",
    "print \"True\", metrics.accuracy_score(y_test[y_test == 1], preds_hat[y_test == 1])\n",
    "print \"False\", metrics.accuracy_score(y_test[y_test == 0], preds_hat[y_test == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.806451612903\n",
      "recall 0.892857142857\n",
      "f1 0.847457627119\n",
      "True 0.892857142857\n",
      "False 0.980456026059\n"
     ]
    }
   ],
   "source": [
    "print \"precision\", metrics.precision_score(y, preds)\n",
    "print \"recall\", metrics.recall_score(y, preds)\n",
    "print \"f1\", metrics.f1_score(y, preds)\n",
    "print \"True\", metrics.accuracy_score(y[y == 1], preds[y == 1])\n",
    "print \"False\", metrics.accuracy_score(y[y == 0], preds[y == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('models/svm.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 'lexical_entailment/bless2011/data_lex_test.tsv'\n",
    "test = pd.read_csv(fp, sep='\\t', header=None)\n",
    "test_vectorized = pd.read_csv('lexical_entailment/bless2011/data_lex_test_vectorized.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.406113537118\n",
      "recall 0.343173431734\n",
      "f1 0.372\n",
      "True 0.343173431734\n",
      "False 0.958358848745\n",
      "271 229 358\n",
      "val : percentage non-nan correct: 0.911224201301\n",
      "val : percentage correct overall 9.00279329609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df = test_vectorized\n",
    "test_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = test_df.iloc[:, :-1]\n",
    "y = test_df.iloc[:, -1]\n",
    "\n",
    "preds = clf.predict(X)\n",
    "true_count = y.sum()\n",
    "preds_count = preds.sum()\n",
    "print \"precision\", metrics.precision_score(y, preds)\n",
    "print \"recall\", metrics.recall_score(y, preds)\n",
    "print \"f1\", metrics.f1_score(y, preds)\n",
    "print \"True\", metrics.accuracy_score(y[y == 1], preds[y == 1])\n",
    "print \"False\", metrics.accuracy_score(y[y == 0], preds[y == 0])\n",
    "print true_count, preds_count, orig_rows\n",
    "\n",
    "num_correct = metrics.accuracy_score(y, preds, normalize=False)\n",
    "\n",
    "print test_name, \": percentage non-nan correct:\", num_correct/float(test_df.shape[0])\n",
    "print test_name, \": percentage correct overall\", num_correct/float(orig_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method concat\n"
     ]
    }
   ],
   "source": [
    "#Vectorize train/test/val sets\n",
    "\n",
    "path_to_dataset = 'lexical_entailment/turney2014/data_lex_val.tsv'\n",
    "path_to_vectorized = 'lexical_entailment/turney2014/data_lext_val_vectorized.tsv'\n",
    "df = pd.read_csv(path_to_dataset, sep='\\t', header=None)\n",
    "\n",
    "words_0 = df[0]\n",
    "words_1 = df[1]\n",
    "y = df[[2]]\n",
    "method = 'concat'\n",
    "def vectorize_word(word):\n",
    "\tif word in model.wv:\n",
    "\t\treturn pd.Series(model.wv[word])\n",
    "\telse:\n",
    "\t\t# The pretrained word2vec model has dimensionality 300\n",
    "\t\treturn pd.Series([0] * 300)\n",
    "\n",
    "vectors_0 = words_0.apply(vectorize_word)\n",
    "vectors_1 = words_1.apply(vectorize_word)\n",
    "def merge_vectors(v1, v2, method):\n",
    "\tprint \"method\", method\n",
    "\t# Concat\n",
    "\tif method == 'concat':\n",
    "\t\treturn pd.concat([vectors_0, vectors_1, y], axis = 1)\n",
    "\telif method == 'diff':\n",
    "\t\t# Roller 2014 says to normalize the difference\n",
    "\t\tdiff = vectors_0 - vectors_1\n",
    "\t\treturn pd.concat([diff, y], axis = 1)\n",
    "\telif method == 'asym':\n",
    "\t\tprint \"asym\"\n",
    "\t\t# diff\n",
    "\t\ta = vectors_0 - vectors_1\n",
    "\t\t# squared diff - can't tell if they mean the mag^2 or ea element sq?\n",
    "\t\tb = pd.DataFrame(np.sqrt(np.square(a.values).sum(axis=1)))\n",
    "\t\treturn pd.concat([a, b, y], axis = 1)\n",
    "\telif method == 'cosine':\n",
    "\t\t#this fails???\n",
    "\t\tprint \"cosine\"\n",
    "\t\tcos = pd.DataFrame(cosine_similarity(vectors_0.values, vectors_1.values).diagonal())\n",
    "\t\treturn pd.concat([v1, v2, cos, y], axis = 1)\n",
    "\n",
    "vectors_x = merge_vectors(vectors_0, vectors_1, method)\n",
    "vectors_x.to_csv(path_to_vectorized, sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absentia</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accounting</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activist</td>\n",
       "      <td>federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>advisories</td>\n",
       "      <td>federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aerospace</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agency</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agriculture</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ambassador</td>\n",
       "      <td>chairman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amendment</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>appeal</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>appeal</td>\n",
       "      <td>ruling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>appointment</td>\n",
       "      <td>chairman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>approval</td>\n",
       "      <td>ruling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>argument</td>\n",
       "      <td>appeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>argument</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>argument</td>\n",
       "      <td>challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>argument</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>argument</td>\n",
       "      <td>concensus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>argument</td>\n",
       "      <td>criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>argument</td>\n",
       "      <td>defendant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>argument</td>\n",
       "      <td>determination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>argument</td>\n",
       "      <td>divide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>argument</td>\n",
       "      <td>evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>argument</td>\n",
       "      <td>excuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>argument</td>\n",
       "      <td>flexibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>argument</td>\n",
       "      <td>foundation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>argument</td>\n",
       "      <td>inconsistency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>argument</td>\n",
       "      <td>judge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>argument</td>\n",
       "      <td>lawsuit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>suit</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>supervision</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>supervision</td>\n",
       "      <td>privatisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>suspension</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>system</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>takeover</td>\n",
       "      <td>privatisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>team</td>\n",
       "      <td>match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>text</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>text</td>\n",
       "      <td>ruling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>theory</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>tournament</td>\n",
       "      <td>match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>transition</td>\n",
       "      <td>privatisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>transport</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>transport</td>\n",
       "      <td>management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>trap</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>treasurer</td>\n",
       "      <td>chairman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>treaty</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>trend</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>union</td>\n",
       "      <td>federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>union</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>verdict</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>verdict</td>\n",
       "      <td>ruling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>verdict</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>willingness</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>wing</td>\n",
       "      <td>federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>winner</td>\n",
       "      <td>match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>witness</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>woo</td>\n",
       "      <td>sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>wrangling</td>\n",
       "      <td>argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>yield</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0              1\n",
       "0       absentia       sentence\n",
       "1     accounting     management\n",
       "2       activist     federation\n",
       "3     advisories     federation\n",
       "4      aerospace     management\n",
       "5         agency     government\n",
       "6    agriculture    environment\n",
       "7    agriculture     management\n",
       "8     ambassador       chairman\n",
       "9      amendment           bill\n",
       "10        appeal       argument\n",
       "11        appeal         ruling\n",
       "12   appointment       chairman\n",
       "13      approval         ruling\n",
       "14      argument         appeal\n",
       "15      argument           bias\n",
       "16      argument      challenge\n",
       "17      argument      complaint\n",
       "18      argument      concensus\n",
       "19      argument      criticism\n",
       "20      argument      defendant\n",
       "21      argument  determination\n",
       "22      argument         divide\n",
       "23      argument       evidence\n",
       "24      argument         excuse\n",
       "25      argument    flexibility\n",
       "26      argument     foundation\n",
       "27      argument  inconsistency\n",
       "28      argument          judge\n",
       "29      argument        lawsuit\n",
       "..           ...            ...\n",
       "591         suit       argument\n",
       "592  supervision     management\n",
       "593  supervision  privatisation\n",
       "594   suspension       sentence\n",
       "595       system    environment\n",
       "596     takeover  privatisation\n",
       "597         team          match\n",
       "598         text           bill\n",
       "599         text         ruling\n",
       "600       theory       argument\n",
       "601   tournament          match\n",
       "602   transition  privatisation\n",
       "603    transport    environment\n",
       "604    transport     management\n",
       "605         trap       sentence\n",
       "606    treasurer       chairman\n",
       "607       treaty           bill\n",
       "608        trend    environment\n",
       "609        union     federation\n",
       "610        union     government\n",
       "611      verdict       argument\n",
       "612      verdict         ruling\n",
       "613      verdict       sentence\n",
       "614  willingness       argument\n",
       "615         wing     federation\n",
       "616       winner          match\n",
       "617      witness       argument\n",
       "618          woo       sentence\n",
       "619    wrangling       argument\n",
       "620        yield           bill\n",
       "\n",
       "[621 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
